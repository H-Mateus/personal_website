{
  "hash": "d5b9945b7ff767e3a3f61304e20ff805",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: How might science be done better?\ndate: '2021-05-11'\ncategories:\n  - Academia\n  - Reproducible Research\n  - Fantasising\nsubtitle: 'The idle daydreaming of a PhD student'\ndescription: 'A follow-up to The Sovereign of Science, exploring how we might improve the way science is done '\ndate-modified: '2021-05-11'\nfeatured: no\nimage: featured.jpg\n  # caption: 'Image credit: **[Unsplash](https://unsplash.com/photos/B5LGz92kaAM)**'\n  # focal_point: ''\n  # preview_only: no\n---\n\n\n\nSo in my previous article on [The Sovereign of Science](../../../../post/the-sovereign-of-science/), I ranted about how I feel the reproducibility issues science face are a result of the lack of feedback scientists receive pertaining to the quality of their work.\nOr, to put it more simply, none of the masters of science (the funding bodies, journals and universities) care if their science is any good, and so it inevitably isn't.\n\nHopefully we can agree that this isn't ideal.\n\n<p style=\"text-align: center;\"><b>But what can we do about?</b></p>\n\nWell I can't do much as a lowly PhD student.\nI simply don't have the power.\nHowever, if you happen to be head of a major funding body, and have presumably been struck by some strange cosmic radiation that has inspired you to suddenly realise you should probably care about the quality of the science you fund, then I have ideas.\n\nI should stress that I don't think these ideas are perfect.\nBut I do feel they outline an objectively better way of doing science, that saves scientists time, saves money, and finally rewards scientists for doing quality research, thus improving the quality of science as a whole and eventually addressing the reproducibility problem.\n\n# Firstly: The journals gotta go\n\n(ref:exit) And never come back! Image credit: [**Unsplash**](https://unsplash.com/photos/mTehrY1mH-s)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![(ref:exit)](exit.jpg){fig-align='center' width=50%}\n:::\n:::\n\n\nSeriously.\nThe only contributions to science they make are harmful ones:\n\n- They reduce the accessibility of science by locking it behind paywalls\n- They [don't care about quality](https://www.theguardian.com/commentisfree/2013/dec/09/how-journals-nature-science-cell-damage-science)\n- They steal [billions from both funders and universities](https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science)\n\nSo why put up with them?\n\n<p style=\"text-align: center;\"><b>I propose that the major research councils either, take 1% of what they spend a year on open access fees, and instead create a new platform where the research they fund will be published, or just throw their weight behind the [Peer Community in](https://peercommunityin.org/).</b></p>\n\nThe latter makes more sense to me as it'd require less effort on their part, but I propose the former as I suspect the people who run these bodies may prefer to create their own initiative for egotistical reasons.\nNot that I'm cynical...\n\n# A new publication model\n\n(ref:newspaper) Image credit: [**Unsplash**](https://unsplash.com/photos/UJ7Udasi4iE)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![(ref:newspaper)](publish.jpg){fig-align='center' width=60%}\n:::\n:::\n\n\nAll the work published here will of course be freely available.\nIn order to publish, authors would be required to create an account, with their real name, contact information and crucially, their research institution.\n\n<p style=\"text-align: center;\"><b>This is so the platform has no anonymity and both individual scientists, and their institutions can be held accountable for any poor behaviour.</b></p>\n\nAs soon as a paper is uploaded by the authors, it would only be viewable by peer reviewers.\nBefore the paper is freely viewable, the authors would be required to review as many papers as their own has authors.\nSo if the paper has 5 authors, they must peer review 5 papers.\nThis could all be done by one author, each author could do 1, or anything in between.\n\n<p style=\"text-align: center;\"><b>This ensures that there will always be enough peer reviewers available.</b></p>\n\nOnce they have completed this requirement, the paper would go live.\nIf the paper has received at least 2 peer reviews supporting the quality of the work, it would be designated as having been reviewed and approved.\nIf not, it would instead be designated as \"under review\".\n\n# Rethinking peer review\n\n(ref:typewriter) Image credit: [**Unsplash**](https://unsplash.com/photos/-fRAIQHKcc0)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![(ref:typewriter)](review.jpg){fig-align='center'}\n:::\n:::\n\n\nHere is what I suspect will be my most controversial suggestion:\n\n<p style=\"text-align: center;\"><b>The peer review process should be completely transparent.</b></p>\n\nI haven't really addressed this till now, but you may have thought something along the lines of:\n\n\"Isn't the peer review process supposed to ensure only good science gets published?\"\n\nAnd yeah, that sure is what it's supposed to do.\nUnfortunately, the state of science clearly shows it isn't working well enough.\nThe peer review process is anonymous, so authors never know the identity of their reviewers, and the comments they make are also never made public.\n\nThe argument in favour of this system is that it allows the reviews to speak freely, without fear that the authors may retaliate by refusing collaborations, or returning harsher reviews of their own work.\nIn smaller fields the authors and reviewers may well know one another personally, and so a transparent system could also be a source of conflict.\n\nI disagree with this assessment.\nIf peer review were completely public, and either a reviewer or author/s behaved poorly, they could warned, denied future funding or even removed by their own institution, as this behaviour would reflect poorly on them as well.\nI suspect this would be enough to keep peer review civil.\n\nIt would also allow us to hold peer reviewers to account if they give bad science a pass.\nBut why would they ever do that?\nWell, as I touched on in the [prior post](../../../../post/the-sovereign-of-science/), scientists are often woefully statistically incompetent, so even if they read the paper properly, they may be too ignorant to notice poor practices such as a study being underpowered, or data not meeting the assumptions of the statical tests performed.\n\nAnd remember, peer reviewers are volunteers, they don't get paid or rewarded at all for their time under the current system.\n\nSo imagine: you are invited to review a paper in your field.\nYou accept, thinking you aren't too busy at the minute and you'll be able to squeeze it in.\nBut then you remember the abstract deadline for a conference is fast approaching.\nYou also need to finish writing some grants.\nAnd you have your own papers to write, teaching to do, and stupid university bureaucracy to waste your time on.\nSo you forget about the paper you said you'd review until the editor says the deadlines approaching soon.\nNow you're really scrambling.\nYou quickly skim through the paper, hope the other reviewer reads it properly and give the authors the benefit of the doubt that it's probably fine.\n\nAgain, there's no reward for doing this at all, let alone for doing it well, and no punishment if you do it poorly.\nSo you cut corners.\nAnd this is how at lot of science goes.\n\nThe opposite can also happen, where a reviewer just doesn't like your results and gives you a hard time, but as an author you ***need*** their approval to publish, so you end up doing whatever they want, even if you don't really agree with them.\n\nBy making the whole process open, it forces both authors and peer reviewers to take it seriously and do it well.\nAnd even once a paper has been reviewed twice, it could still be reviewed by other academics if they feel they've something to add.\nThis way, even if both the first reviewers miss something, it's very likely that someone else will eventually notice an issue and publicly notify the authors.\n\nA system like this also lends itself well to making small tweaks.\nPerhaps early career researchers could get something like a \"learner\" badge, where their peer reviews are only worth half as much as more experienced colleagues.\nPhD students could be required to do a certain number of peer reviews in order to be awarded their doctorate.\n\nTo add to this, I would show the latest iteration of a given paper on the website, but I would allow users to go back and see each prior version of the paper.\nThis could be particularly useful for students to learn from.\n\n# Providing a reason to care about reproducibility\n\n(ref:sharing) Image credit: [**Kristian Niemi**](https://search.creativecommons.org/photos/2207415d-ea6c-4c18-b609-59437b957d0d)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![(ref:sharing)](care.jpg){fig-align='center'}\n:::\n:::\n\n\nI would also propose papers be given some kind of \"reproducibility score\".\nI imagine this functioning like a checklist:\n\n- Is the raw experimental data published?\n- Is the paper itself written in plain text, with reproducible figures/tables?\n- Is the script/s used to analyse the data included?\n- Is the software used free and open-source?\n- Was [version control](https://git-scm.com/book/en/v2/Getting-Started-About-Version-Control) used for the script/s and/or paper?\n- Is a [container](https://www.docker.com/resources/what-container) with all the software used provided?\n\nIf all the criteria are met, then the paper gets a perfect score.\nThis score could be tacked at both the level of individual scientists, and for institutions.\nThis would serve as a nice lazy indicator as to the quality of the scientist/institution.\nFunding bodies could use this when awarding grants, and postdocs/students could use it to help decide where they work/study.\n\nAs has been suggested elsewhere, I would also provide a separate doi for the paper, data and container, so these can receive citation and the authors can continue to receive proper credit for their work.\n\n<p style=\"text-align: center;\"><b>The key here is that this provides an incentive for scientists to make their research more transparent and reproducible, not to evaluate the impact or even the quality of the work itself.<br>\nThe open peer review should sort that part.<br>\nHopefully...</b></p>\n\nIf their studies are underpowered, or their stats rubbish, this system would make it obvious and easy to call out.\nThis would reflect poorly on the authors, and perhaps more importantly on their institution.\nThus, it would behove them to make sure their researchers are well trained and equipped to follow best practises.\n\n# Sounds great, but who pays for this system?\n\n(ref:coins) Image credit: [**Unsplash**](https://unsplash.com/photos/ZihPQeQR2wM)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![(ref:coins)](money.jpg){fig-align='center'}\n:::\n:::\n\n\nI would suggest a combination of the funding bodies and major research institutions.\nPragmatically, I think it makes sense for universities to provide the servers to host their own research, and for software to automatically back this up to other university servers.\nThis way, even if the servers are damaged/destroyed (in a fire for example), nothing would be lost.\n\nThe cost of this would be extremely low, especially compared to what is currently spent by funders on open access fees, and most definitely less than the [literal billions](https://www.theguardian.com/science/2017/jun/27/profitable-business-scientific-publishing-bad-for-science) universities are spending on journal subscriptions.\nI'm pretty confident this proposed system would cost less than 1% of what is currently spent to both establish and maintain.\nAnd it would mean scientists don't have to waste huge amounts of time bending over backwards to appease asinine journal requirements.\n\nIt's not like putting a .pdf on the internet costs a lot, which effectively all publication entails.\nThis website costs me exactly nothing.\nThe system I'm proposing is effectively just a big distributed website with a particular structure, so the cost would be very low, especially when distributed across all research institutions.\n\n# Feedback welcome\n\n(ref:head) Sometimes I wonder if I'm just too idealistic. Image credit: [**Unsplash**](https://unsplash.com/photos/W_6b8pWBUKY)\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![(ref:head)](madness.jpg){fig-align='center' width=60%}\n:::\n:::\n\n\nThis is of course just my 2 cents.\nAnd I should reiterate, I'm sure these proposals would have their own issues, and certainly introduce some major teething pains.\nBut I still feel it's a big improvement over what we've got.\nIf you've any feedback, positive or negative, it's very welcome.\nIf it's really good I may even update these articles.\n\nPerhaps I'm getting ahead of myself though.\nI didn't write these expecting to start a revolution.\nWe have the system we do because the people with power are either ignorant, apathetic or both, and I don't expect that to change anytime soon.\n\nThis was more an exercise in articulating my thoughts, and getting some of this vitriol out of my head.\nAnd I've enjoyed it, so I'll chalk it up as a win.\n\n**Update:** So embarrassingly enough, when I first wrote this I wasn't aware of the [Peer Community in](https://peercommunityin.org/), which actually makes a lot of good progress in respect to the peer-review side of things, particularly in trying to de-couple peer-review from journals, though I still think some of the other ideas I outline here could improve on their model.\nHaving said that, it's a really cool initiative, and I hope to publish my future work with them where possible!\nI write more about them in [this post](../../../../post/progress-in-open-research/).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}